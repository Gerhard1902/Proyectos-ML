{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2783e420",
   "metadata": {},
   "source": [
    "## Review Project Analysis\n",
    "\n",
    "Help a leading mobile brand understand the voice of the customer by analyzing the reviews of their product on Amazon and the topics that customers are talking about. You will perform topic modeling on specific parts of speech. You’ll finally interpret the emerging topics.\n",
    "\n",
    "Problem Statement: \n",
    "\n",
    "A popular mobile phone brand, Lenovo has launched their budget smartphone in the Indian market. The client wants to understand the VOC (voice of the customer) on the product. This will be useful to not just evaluate the current product, but to also get some direction for developing the product pipeline. The client is particularly interested in the different aspects that customers care about. Product reviews by customers on a leading e-commerce site should provide a good view.\n",
    "\n",
    "Domain: Amazon reviews for a leading phone brand\n",
    "\n",
    "Analysis to be done: POS tagging, topic modeling using LDA, and topic interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad24277f",
   "metadata": {},
   "source": [
    "# 1. Read the .csv file using Pandas. Take a look at the top few records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a1d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "#Library for tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Library for Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Stop words, punctation\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "#Library for Gensim -LDA Model\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a6bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=pd.read_csv(r\"K8 Reviews v0.2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21dd5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Good but need updates and improvements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Worst mobile i have bought ever, Battery is dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>when I will get my 10% cash back.... its alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The worst phone everThey have changed the last...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1             Good but need updates and improvements\n",
       "1          0  Worst mobile i have bought ever, Battery is dr...\n",
       "2          1  when I will get my 10% cash back.... its alrea...\n",
       "3          1                                               Good\n",
       "4          0  The worst phone everThey have changed the last..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53addd",
   "metadata": {},
   "source": [
    "# 2. Normalize casings for the review text and extract the text into a list for easier manipulation.\n",
    "\n",
    "# 3. Tokenize the reviews using NLTKs word_tokenize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eabe268",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokenized = []\n",
    "\n",
    "for sent in reviews.review.values:\n",
    "    reviews_tokenized.append(word_tokenize(sent.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20ee0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'but', 'need', 'updates', 'and', 'improvements']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Watching first review for demonstration purposes\n",
    "reviews_tokenized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721398b3",
   "metadata": {},
   "source": [
    "# 4. Perform parts-of-speech tagging on each sentence using the NLTK POS tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11af29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_reviews = [nltk.pos_tag(word) for word in reviews_tokenized]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aae16265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 'JJ'),\n",
       " ('but', 'CC'),\n",
       " ('need', 'VBP'),\n",
       " ('updates', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('improvements', 'NNS')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6381cc0b",
   "metadata": {},
   "source": [
    "# 5.For the topic model, we should  want to include only nouns.\n",
    "\n",
    "1 Find out all the POS tags that correspond to nouns.\n",
    "\n",
    "2 Limit the data to only terms with these tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0670640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('updates', 'NNS'), ('improvements', 'NNS')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_reviews = []\n",
    "\n",
    "for item in tagged_reviews:\n",
    "    noun_reviews.append([word for word in item if \"NN\" in word[1]])\n",
    "    \n",
    "noun_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bd48e",
   "metadata": {},
   "source": [
    "# 6. Lemmatize. \n",
    "\n",
    "1 Different forms of the terms need to be treated as one.\n",
    "\n",
    "2 No need to provide POS tag to lemmatizer for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1995570",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_review=[]\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "for sentence in noun_reviews:\n",
    "    lemmatized_review.append([lemm.lemmatize(noun[0]) for noun in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed6798",
   "metadata": {},
   "source": [
    "# 7. Remove stopwords and punctuation (if there are any). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39d89cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews=[]\n",
    "\n",
    "my_stopwords = list(stopwords.words('english'))+list(punctuation)\n",
    "my_stopwords.append(\"..\")\n",
    "\n",
    "for sentence in lemmatized_review:\n",
    "    cleaned_reviews.append([noun for noun in sentence if noun not in my_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60c0c874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['update', 'improvement']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a3e04",
   "metadata": {},
   "source": [
    "# 8.Create a topic model using LDA on the cleaned-up data with 12 topics.\n",
    "\n",
    "Print out the top terms for each topic.\n",
    "\n",
    "What is the coherence of the model with the c_v metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9614d31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_TOPICS = 12\n",
    "dictionary = corpora.Dictionary(cleaned_reviews)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in cleaned_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39a9b043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'improvement'), (1, 'update'), (2, 'amazon')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dictionary.items())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3034cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel(corpus=doc_term_matrix, num_topics=12, id2word=dictionary, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "386eed90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0: 0.136*\"charger\" + 0.057*\"delivery\" + 0.045*\"phone\" + 0.043*\"turbo\" + 0.039*\"budget\" + 0.025*\"charging\" + 0.023*\"expectation\" + 0.019*\"till\" + 0.018*\"plz\" + 0.017*\"cable\" + 0.016*\"need\" + 0.015*\"order\"\n",
      "\n",
      "Topic #1: 0.074*\"heat\" + 0.046*\"performance\" + 0.033*\"month\" + 0.032*\"system\" + 0.032*\"phone\" + 0.031*\"battery\" + 0.021*\"problem\" + 0.020*\"thanks\" + 0.020*\"purchase\" + 0.019*\"condition\" + 0.018*\"hour\" + 0.018*\"....\"\n",
      "\n",
      "Topic #2: 0.130*\"price\" + 0.109*\"....\" + 0.086*\"phone\" + 0.042*\"range\" + 0.036*\"everything\" + 0.033*\"camera\" + 0.023*\"feature\" + 0.020*\"worth\" + 0.019*\"product\" + 0.019*\"smartphone\" + 0.017*\"specification\" + 0.013*\"pls\"\n",
      "\n",
      "Topic #3: 0.059*\"phone\" + 0.039*\"call\" + 0.027*\"sim\" + 0.026*\"network\" + 0.025*\"camera\" + 0.022*\"h\" + 0.020*\"video\" + 0.016*\"quality\" + 0.016*\"feature\" + 0.015*\"screen\" + 0.015*\"photo\" + 0.015*\"display\"\n",
      "\n",
      "Topic #4: 0.281*\"phone\" + 0.037*\"amazon\" + 0.033*\"time\" + 0.023*\"issue\" + 0.021*\"superb\" + 0.016*\"replacement\" + 0.015*\"dolby\" + 0.015*\"problem\" + 0.013*\"mobile\" + 0.012*\"lenovo\" + 0.011*\"feature\" + 0.010*\"signal\"\n",
      "\n",
      "Topic #5: 0.172*\"product\" + 0.053*\"phone\" + 0.048*\"camera\" + 0.026*\"lenovo\" + 0.018*\"quality\" + 0.016*\"issue\" + 0.016*\"money\" + 0.013*\"battery\" + 0.012*\"price\" + 0.011*\"day\" + 0.010*\"service\" + 0.010*\"problem\"\n",
      "\n",
      "Topic #6: 0.123*\"problem\" + 0.100*\"heating\" + 0.067*\"waste\" + 0.058*\"money\" + 0.042*\"handset\" + 0.033*\"issue\" + 0.027*\"network\" + 0.025*\"set\" + 0.024*\"processor\" + 0.019*\"awesome\" + 0.013*\"item\" + 0.011*\"response\"\n",
      "\n",
      "Topic #7: 0.157*\"camera\" + 0.123*\"mobile\" + 0.070*\"quality\" + 0.059*\"phone\" + 0.028*\"battery\" + 0.018*\".....\" + 0.018*\"performance\" + 0.014*\"bit\" + 0.011*\"time\" + 0.010*\"feature\" + 0.010*\"front\" + 0.009*\"issue\"\n",
      "\n",
      "Topic #8: 0.181*\"battery\" + 0.086*\"phone\" + 0.036*\"camera\" + 0.034*\"backup\" + 0.028*\"issue\" + 0.026*\"day\" + 0.023*\"life\" + 0.022*\"hour\" + 0.021*\"performance\" + 0.020*\"problem\" + 0.017*\"charge\" + 0.017*\"device\"\n",
      "\n",
      "Topic #9: 0.069*\"hai\" + 0.050*\"value\" + 0.040*\"money\" + 0.033*\"speaker\" + 0.031*\"mark\" + 0.024*\"music\" + 0.023*\"piece\" + 0.019*\"phone\" + 0.018*\"cell\" + 0.017*\"......\" + 0.016*\"experience\" + 0.016*\"app\"\n",
      "\n",
      "Topic #10: 0.054*\"glass\" + 0.048*\"box\" + 0.037*\"super\" + 0.035*\"earphone\" + 0.031*\"gorilla\" + 0.030*\"headphone\" + 0.029*\"phone\" + 0.024*\"cost\" + 0.023*\"warranty\" + 0.018*\"today\" + 0.017*\"resolution\" + 0.017*\"offer\"\n",
      "\n",
      "Topic #11: 0.082*\"note\" + 0.077*\"phone\" + 0.043*\"k8\" + 0.029*\"service\" + 0.029*\"lenovo\" + 0.028*\"screen\" + 0.027*\"issue\" + 0.027*\"option\" + 0.023*\"problem\" + 0.022*\"day\" + 0.013*\"customer\" + 0.012*\"device\"\n"
     ]
    }
   ],
   "source": [
    "for idx in range(12):\n",
    "    print(\"\\nTopic #%s:\" % idx, lda_model.print_topic(idx, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29e8839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.49463728236998034\n"
     ]
    }
   ],
   "source": [
    "lda_coherence_score = CoherenceModel(model=lda_model, texts=cleaned_reviews, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = lda_coherence_score.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78900bb8",
   "metadata": {},
   "source": [
    "# 9. Analyze the topics through the business lens.\n",
    "\n",
    "1 Determine which of the topics can be combined.\n",
    "\n",
    "Based on the LDA model results, it can be inferred that several topics can be combined into the following 6 major categories:\n",
    "\n",
    "Battery Problems - Topic # 0, 8\n",
    "\n",
    "Phone Performance - Topic # 1, 7\n",
    "\n",
    "Pricing - Topic # 2, 6, 9\n",
    "\n",
    "Hardware Issues - Topic # 3\n",
    "\n",
    "Provider´s Service - Topic # 4, 5, 11\n",
    "\n",
    "Phone Accesories - Topic # 10\n",
    "\n",
    "The aforementioned topics represent the main categories being faced by the company according to our analysis performed through the LDA model results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934d3a8",
   "metadata": {},
   "source": [
    "# 10 Create topic model using LDA with what you think is the optimal number of topics\n",
    "\n",
    "What is the coherence of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bfc9d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration 1 Coherence Score: 0.4530977719924728\n",
      "\n",
      " Iteration 2 Coherence Score: 0.5420413053840256\n",
      "\n",
      " Iteration 3 Coherence Score: 0.517223904502231\n",
      "\n",
      " Iteration 4 Coherence Score: 0.4932724626383746\n",
      "\n",
      " Iteration 5 Coherence Score: 0.5296196266830859\n",
      "\n",
      " Iteration 6 Coherence Score: 0.5612164418353448\n",
      "\n",
      " Iteration 7 Coherence Score: 0.5444517913780446\n",
      "\n",
      " Iteration 8 Coherence Score: 0.5352033283337323\n",
      "\n",
      " Iteration 9 Coherence Score: 0.5155521159925478\n",
      "\n",
      " Iteration 10 Coherence Score: 0.5027658134599642\n",
      "\n",
      " Iteration 11 Coherence Score: 0.4943050244058666\n",
      "\n",
      " Iteration 12 Coherence Score: 0.49463728236998034\n",
      "\n",
      " Iteration 13 Coherence Score: 0.5067517543400267\n",
      "\n",
      " Iteration 14 Coherence Score: 0.5124270575030481\n",
      "\n",
      " Iteration 15 Coherence Score: 0.5284891406927803\n",
      "\n",
      " Iteration 16 Coherence Score: 0.5086458544214055\n",
      "\n",
      " Iteration 17 Coherence Score: 0.5022565482463999\n",
      "\n",
      " Iteration 18 Coherence Score: 0.48506598649201993\n",
      "\n",
      " Iteration 19 Coherence Score: 0.506188812618673\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for i in range (20):\n",
    "     if i != 0:\n",
    "        lda_model2 = models.LdaModel(corpus=doc_term_matrix, num_topics=i, id2word=dictionary, random_state=31)\n",
    "        lda_coherence_score2 = CoherenceModel(model=lda_model2, texts=cleaned_reviews, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_lda2 = lda_coherence_score2.get_coherence()\n",
    "        print('\\n Iteration {} Coherence Score: {}'.format(i, coherence_lda2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f95fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel(corpus=doc_term_matrix, num_topics=6, id2word=dictionary, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8467c851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0: 0.025*\"charger\" + 0.019*\"super\" + 0.018*\"box\" + 0.017*\"piece\" + 0.015*\"device\" + 0.015*\"earphone\" + 0.013*\"awesome\" + 0.011*\"star\" + 0.011*\"hai\" + 0.008*\"gud\" + 0.008*\"bill\" + 0.007*\"ko\"\n",
      "\n",
      "Topic #1: 0.119*\"battery\" + 0.032*\"hour\" + 0.028*\"backup\" + 0.021*\"problem\" + 0.020*\"phone\" + 0.019*\"charge\" + 0.016*\"issue\" + 0.015*\"charger\" + 0.015*\"h\" + 0.014*\"heat\" + 0.013*\"time\" + 0.012*\"month\"\n",
      "\n",
      "Topic #2: 0.122*\"camera\" + 0.081*\"phone\" + 0.057*\"battery\" + 0.057*\"quality\" + 0.038*\"performance\" + 0.030*\"price\" + 0.029*\"....\" + 0.024*\"feature\" + 0.015*\"everything\" + 0.014*\"life\" + 0.013*\"backup\" + 0.012*\"budget\"\n",
      "\n",
      "Topic #3: 0.060*\"phone\" + 0.032*\"camera\" + 0.019*\"screen\" + 0.018*\"issue\" + 0.016*\"network\" + 0.015*\"battery\" + 0.015*\"speaker\" + 0.014*\"call\" + 0.014*\"sim\" + 0.012*\"quality\" + 0.011*\"feature\" + 0.011*\"display\"\n",
      "\n",
      "Topic #4: 0.159*\"phone\" + 0.057*\"mobile\" + 0.037*\"problem\" + 0.032*\"note\" + 0.029*\"issue\" + 0.020*\"time\" + 0.019*\"k8\" + 0.018*\"lenovo\" + 0.018*\"amazon\" + 0.015*\"heating\" + 0.013*\"battery\" + 0.012*\"update\"\n",
      "\n",
      "Topic #5: 0.107*\"product\" + 0.049*\"phone\" + 0.038*\"camera\" + 0.030*\"money\" + 0.018*\"quality\" + 0.017*\"price\" + 0.016*\"service\" + 0.016*\"lenovo\" + 0.015*\"waste\" + 0.013*\"day\" + 0.012*\"range\" + 0.012*\"battery\"\n"
     ]
    }
   ],
   "source": [
    "for idx in range(6):\n",
    "    print(\"\\nTopic #%s:\" % idx, lda_model.print_topic(idx, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeeb89d",
   "metadata": {},
   "source": [
    "# 11. The business should  be able to interpret the topics.\n",
    "\n",
    "Name each of the identified topics.\n",
    "\n",
    "Create a table with the topic name and the top 10 terms in each to present to the  business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4820939",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda_model.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46e8dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories=[\"Phone Accesories\",\"Battery Problems\", \"Phone Performance\", \"Hardware Issues\", \"Provider´s Service\", \"Pricing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c11c89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g= pd.DataFrame(topics)\n",
    "Topic_DF= g[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "863239ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charger',\n",
       " 'super',\n",
       " 'box',\n",
       " 'piece',\n",
       " 'device',\n",
       " 'earphone',\n",
       " 'awesome',\n",
       " 'star',\n",
       " 'hai',\n",
       " 'gud']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table = []\n",
    "for topic in Topic_DF:\n",
    "        Table.append([word[0] for word in topic])\n",
    "    \n",
    "Table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b463a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "DataFrame= pd.DataFrame({'Topic': Categories, 'Top Terms':Table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5eafbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3a14e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Topic</th>\n",
       "      <th class=\"col_heading level0 col1\" >Top Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_3a14e_row0_col0\" class=\"data row0 col0\" >Phone Accesories</td>\n",
       "      <td id=\"T_3a14e_row0_col1\" class=\"data row0 col1\" >['charger', 'super', 'box', 'piece', 'device', 'earphone', 'awesome', 'star', 'hai', 'gud']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3a14e_row1_col0\" class=\"data row1 col0\" >Battery Problems</td>\n",
       "      <td id=\"T_3a14e_row1_col1\" class=\"data row1 col1\" >['battery', 'hour', 'backup', 'problem', 'phone', 'charge', 'issue', 'charger', 'h', 'heat']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3a14e_row2_col0\" class=\"data row2 col0\" >Phone Performance</td>\n",
       "      <td id=\"T_3a14e_row2_col1\" class=\"data row2 col1\" >['camera', 'phone', 'battery', 'quality', 'performance', 'price', '....', 'feature', 'everything', 'life']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3a14e_row3_col0\" class=\"data row3 col0\" >Hardware Issues</td>\n",
       "      <td id=\"T_3a14e_row3_col1\" class=\"data row3 col1\" >['phone', 'camera', 'screen', 'issue', 'network', 'battery', 'speaker', 'call', 'sim', 'quality']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3a14e_row4_col0\" class=\"data row4 col0\" >Provider´s Service</td>\n",
       "      <td id=\"T_3a14e_row4_col1\" class=\"data row4 col1\" >['phone', 'mobile', 'problem', 'note', 'issue', 'time', 'k8', 'lenovo', 'amazon', 'heating']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_3a14e_row5_col0\" class=\"data row5 col0\" >Pricing</td>\n",
       "      <td id=\"T_3a14e_row5_col1\" class=\"data row5 col1\" >['product', 'phone', 'camera', 'money', 'quality', 'price', 'service', 'lenovo', 'waste', 'day']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e3630dd580>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454a45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
